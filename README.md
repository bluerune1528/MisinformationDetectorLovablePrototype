# ğŸ§  Misinformation Detector â€” AI-Assisted Web Application (Prototype)

An AI-assisted web application that analyzes text or web URLs to detect potential misinformation using **LLM reasoning, web verification, fact-checking APIs, and hybrid scoring techniques**.

Developed as part of the **Project Based Learning & Management (PBLM-2)**.

---

## ğŸ“Œ Project Overview

The rapid spread of misinformation across digital platforms makes automated credibility assessment essential. This project provides a system that evaluates user-submitted content using a combination of:

* Large Language Model (LLM) analysis
* Real-time web search verification
* Fact-checking services
* Heuristic scoring methods

The application accepts both **plain text** and **URLs**, analyzes the information contextually, and generates a credibility score with explanations.

---

## âœ¨ Features

* âœ… Text misinformation detection
* âœ… URL-based article analysis
* âœ… LLaMA-powered AI reasoning
* âœ… Real-time web verification (Tavily search)
* âœ… Fact-check API integration
* âœ… Hybrid credibility scoring system
* âœ… Explanation-based results
* âœ… Analysis history tracking
* âœ… Modern responsive UI
* âœ… Cloud deployment

---

## ğŸ§  Detection Pipeline

```
User Input (Text / URL)
            â†“
Input Classifier
            â†“
URL â†’ Jina Reader (Article Extraction)
Text â†’ Direct Processing
            â†“
Content Normalization
            â†“
Tavily Web Verification
            â†“
Fact-Check API Validation
            â†“
LLaMA AI Analysis
            â†“
Hybrid Scoring Engine
            â†“
Result + Explanation + History Storage
```

---

## âš™ï¸ Technologies Used

### ğŸ–¥ï¸ Frontend

* React
* TypeScript
* Vite
* Tailwind CSS
* shadcn/ui

### ğŸ§  AI & APIs

LLaMA API â€” contextual misinformation analysis using Large Language Models

Tavily API â€” real-time web search and evidence retrieval

Fact Check API â€” verification against known fact-check databases

Jina Reader API â€” webpage content extraction and text cleaning from URLs for analysis

### ğŸ” Detection Methods

* Heuristic rule-based analysis
* AI semantic reasoning
* Source verification
* Hybrid credibility scoring algorithm

### ğŸ—„ï¸ Backend & Database

* Supabase

  * History storage
  * Backend services
  * API integration support

### ğŸš€ Development & Deployment

* Lovable (AI-assisted development environment)
* GitHub (version control)
* Vercel (hosting & continuous deployment)
* Node.js runtime

---

## ğŸ“‚ Project Structure

```
src/
 â”œâ”€â”€ components/        UI components
 â”œâ”€â”€ pages/             Application pages
 â”œâ”€â”€ services/          API integrations
 â”œâ”€â”€ analysis/          Scoring & detection logic
 â””â”€â”€ integrations/      Supabase connection

supabase/               Database configuration
public/                 Static assets
vite.config.ts          Build configuration
```

---

## ğŸ§ª How It Works

### 1ï¸âƒ£ Input Detection

The system determines whether the user input is:

* plain text, or
* a web URL.

### 2ï¸âƒ£ Content Processing

* URLs are parsed and article content is extracted.
* Text is cleaned and prepared for analysis.

### 3ï¸âƒ£ Verification Stage

* Tavily searches supporting or contradicting sources.
* Fact-check APIs validate known claims.

### 4ï¸âƒ£ AI Analysis

The LLaMA model evaluates:

* claim plausibility
* linguistic patterns
* contextual consistency
* misinformation indicators.

### 5ï¸âƒ£ Hybrid Scoring

A combined score is calculated using:

* AI confidence
* fact-check matches
* source reliability
* heuristic penalties

### 6ï¸âƒ£ Output

The system returns:

* Credibility score
* Classification result
* Explanation summary

---

## ğŸš€ Local Setup

### Clone Repository

```bash
git clone https://github.com/bluerune1528/MisinformationDetectorLovablePrototype.git
cd MisinformationDetectorLovablePrototype
```

### Install Dependencies

```bash
npm install
```

### Create `.env` File

```
VITE_SUPABASE_URL=
VITE_SUPABASE_ANON_KEY=
VITE_LLAMA_API_KEY=
VITE_TAVILY_API_KEY=
VITE_FACTCHECK_API_KEY=
```

*(Environment variables are not committed to GitHub for security.)*

### Run Locally

```bash
npm run dev
```

Open:

```
http://localhost:5173
```

---

## ğŸŒ Deployment Workflow

1. Development performed using Lovable.
2. Changes automatically synced to GitHub.
3. GitHub triggers automatic deployment on Vercel.
4. Live website updates after successful builds.

---

## ğŸ”® Future Improvements

* Advanced NLP fine-tuned models
* Source credibility knowledge base
* Sentiment & bias detection
* Multi-language misinformation detection
* Explainable AI visualization
* Real-time social media integration

---

## âš ï¸ Disclaimer

This system provides automated credibility assistance and should not be considered a definitive fact-checking authority. Users should verify critical information from trusted sources.

---

## ğŸ‘¨â€ğŸ’» Contributors

* Add Team Members

---

## ğŸ“„ License

Educational and research purposes only.

---
